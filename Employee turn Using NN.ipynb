{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee TurnOver prediction using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"Downloads/HR_comma_sep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting the categorical columns to numbers, by converting them to dummy variables. Dummy variables are usually ones and zeros that indicate the presence or absence of a categorical feature. In this kind of situation avoiding the dummy variable trap by dropping the first dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['sales','salary']\n",
    "df_final = pd.get_dummies(df,columns=feats,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Your Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use scikit-learn to split your dataset into a training and a testing set. This is necessary so you can use part of the employee data to train the model and a part of it to test its performance.\n",
    "I will use 70% of the data for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_final.drop(['left'],axis=1).values\n",
    "y = df_final['left'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building Deep Learning models it is usually good practice to scale the dataset in order to make the computations more efficient. In this step, scale the data using the StandardScaler; this will ensure that the dataset values have a mean of zero and a unit variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use keras to build the deep learning model.\n",
    "\n",
    "When building a Deep Learning model you usually specify three layer types:\n",
    "\n",
    "* The input layer is the layer to which pass the features of the dataset. There is no computation that occurs in this layer. It serves to pass features to the hidden layers.\n",
    "* The hidden layers are usually the layers between the input layer and the output layer and there can be more than one. These layers perform the computations and pass the information to the output layer.\n",
    "* The output layer represents the layer of your neural network that will give the results after training the model. It is responsible for producing the output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification problem is a task where you have labeled data and would like to make some predictions based on the labeled data. Add this code to your notebook to create a classifier variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.2344 - accuracy: 0.9244\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 1s 764us/step - loss: 0.1853 - accuracy: 0.9450\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.1701 - accuracy: 0.9509\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 1s 791us/step - loss: 0.1643 - accuracy: 0.9518\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 1s 972us/step - loss: 0.1618 - accuracy: 0.9526\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 1s 979us/step - loss: 0.1598 - accuracy: 0.9530\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 1s 847us/step - loss: 0.1583 - accuracy: 0.9545\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 1s 882us/step - loss: 0.1570 - accuracy: 0.9546\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 1s 863us/step - loss: 0.1556 - accuracy: 0.9553\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 1s 804us/step - loss: 0.1546 - accuracy: 0.9552\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 1s 749us/step - loss: 0.1533 - accuracy: 0.9562\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 1s 760us/step - loss: 0.1523 - accuracy: 0.9559\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 1s 817us/step - loss: 0.1516 - accuracy: 0.9552\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 1s 793us/step - loss: 0.1508 - accuracy: 0.9565\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.1499 - accuracy: 0.9565\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 1s 881us/step - loss: 0.1492 - accuracy: 0.9567\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 1s 904us/step - loss: 0.1481 - accuracy: 0.9581\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 1s 855us/step - loss: 0.1476 - accuracy: 0.9562\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 1s 830us/step - loss: 0.1467 - accuracy: 0.9575\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 1s 813us/step - loss: 0.1465 - accuracy: 0.9573\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 1s 847us/step - loss: 0.1460 - accuracy: 0.9576\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1454 - accuracy: 0.9580\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 1s 926us/step - loss: 0.1448 - accuracy: 0.9574\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9574\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 1s 766us/step - loss: 0.1439 - accuracy: 0.9575\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 1s 775us/step - loss: 0.1439 - accuracy: 0.9576\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 1s 786us/step - loss: 0.1432 - accuracy: 0.9579\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 1s 759us/step - loss: 0.1432 - accuracy: 0.9580\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 1s 823us/step - loss: 0.1425 - accuracy: 0.9584\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 1s 769us/step - loss: 0.1423 - accuracy: 0.9584\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 1s 747us/step - loss: 0.1420 - accuracy: 0.9581\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 1s 749us/step - loss: 0.1411 - accuracy: 0.9581\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 1s 816us/step - loss: 0.1410 - accuracy: 0.9587\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 1s 841us/step - loss: 0.1410 - accuracy: 0.9585\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 1s 767us/step - loss: 0.1401 - accuracy: 0.9589\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 1s 801us/step - loss: 0.1398 - accuracy: 0.9590\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 1s 767us/step - loss: 0.1395 - accuracy: 0.9584\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 1s 753us/step - loss: 0.1395 - accuracy: 0.9586\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 1s 764us/step - loss: 0.1390 - accuracy: 0.9587\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 1s 759us/step - loss: 0.1387 - accuracy: 0.9596\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 1s 752us/step - loss: 0.1385 - accuracy: 0.9596\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 1s 937us/step - loss: 0.1380 - accuracy: 0.9592\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 1s 895us/step - loss: 0.1378 - accuracy: 0.9599\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 1s 761us/step - loss: 0.1381 - accuracy: 0.9595\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 1s 773us/step - loss: 0.1374 - accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.1371 - accuracy: 0.9602\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 1s 799us/step - loss: 0.1372 - accuracy: 0.9606\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 1s 762us/step - loss: 0.1369 - accuracy: 0.9606\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 1s 782us/step - loss: 0.1368 - accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 1s 845us/step - loss: 0.1368 - accuracy: 0.9611\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 1s 826us/step - loss: 0.1365 - accuracy: 0.9605\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 1s 759us/step - loss: 0.1367 - accuracy: 0.9593\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 1s 777us/step - loss: 0.1362 - accuracy: 0.9606\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 1s 784us/step - loss: 0.1362 - accuracy: 0.9615\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 1s 803us/step - loss: 0.1359 - accuracy: 0.9602\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 1s 863us/step - loss: 0.1363 - accuracy: 0.9614\n",
      "Epoch 57/100\n",
      "1050/1050 [==============================] - 1s 796us/step - loss: 0.1358 - accuracy: 0.9607\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 1s 772us/step - loss: 0.1358 - accuracy: 0.9603\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 1s 793us/step - loss: 0.1354 - accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 1s 779us/step - loss: 0.1359 - accuracy: 0.9607\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 1s 957us/step - loss: 0.1356 - accuracy: 0.9603\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 1s 861us/step - loss: 0.1352 - accuracy: 0.9609\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 1s 825us/step - loss: 0.1353 - accuracy: 0.9614\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 1s 790us/step - loss: 0.1355 - accuracy: 0.9608\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 1s 830us/step - loss: 0.1353 - accuracy: 0.9603\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 1s 775us/step - loss: 0.1353 - accuracy: 0.9611\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1348 - accuracy: 0.9605\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 1s 784us/step - loss: 0.1348 - accuracy: 0.9611\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1350 - accuracy: 0.9609\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1349 - accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 1s 769us/step - loss: 0.1344 - accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 1s 772us/step - loss: 0.1346 - accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 1s 778us/step - loss: 0.1344 - accuracy: 0.9609\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 1s 777us/step - loss: 0.1343 - accuracy: 0.9610\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 1s 792us/step - loss: 0.1345 - accuracy: 0.9603\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1345 - accuracy: 0.9598\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 1s 805us/step - loss: 0.1346 - accuracy: 0.9610\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 1s 993us/step - loss: 0.1341 - accuracy: 0.9609\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 1s 889us/step - loss: 0.1340 - accuracy: 0.9602\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1341 - accuracy: 0.9609\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 1s 756us/step - loss: 0.1342 - accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1341 - accuracy: 0.9609\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 1s 739us/step - loss: 0.1340 - accuracy: 0.9611\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 1s 725us/step - loss: 0.1340 - accuracy: 0.9611\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 1s 745us/step - loss: 0.1336 - accuracy: 0.9603\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 1s 735us/step - loss: 0.1340 - accuracy: 0.9603\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 1s 733us/step - loss: 0.1336 - accuracy: 0.9606\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 1s 729us/step - loss: 0.1338 - accuracy: 0.9612\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 1s 737us/step - loss: 0.1339 - accuracy: 0.9609\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 1s 737us/step - loss: 0.1339 - accuracy: 0.9605\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 1s 758us/step - loss: 0.1338 - accuracy: 0.9609\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 1s 752us/step - loss: 0.1339 - accuracy: 0.9602\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 1s 732us/step - loss: 0.1336 - accuracy: 0.9613\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 1s 742us/step - loss: 0.1336 - accuracy: 0.9611\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 1s 733us/step - loss: 0.1334 - accuracy: 0.9608\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 1s 735us/step - loss: 0.1333 - accuracy: 0.9612\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 1s 734us/step - loss: 0.1332 - accuracy: 0.9605\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 1s 747us/step - loss: 0.1333 - accuracy: 0.9607\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 1s 817us/step - loss: 0.1333 - accuracy: 0.9607\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 1s 948us/step - loss: 0.1329 - accuracy: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27feeb93a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 1s 769us/step - loss: 0.1327 - accuracy: 0.9605\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1326 - accuracy: 0.9613\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 1s 812us/step - loss: 0.1327 - accuracy: 0.9609\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 1s 768us/step - loss: 0.1320 - accuracy: 0.9605\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 1s 747us/step - loss: 0.1317 - accuracy: 0.9611\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 1s 804us/step - loss: 0.1318 - accuracy: 0.9603\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 1s 753us/step - loss: 0.1317 - accuracy: 0.9617\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 1s 782us/step - loss: 0.1318 - accuracy: 0.9608\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 1s 767us/step - loss: 0.1318 - accuracy: 0.9609\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 1s 762us/step - loss: 0.1317 - accuracy: 0.9607\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 1s 766us/step - loss: 0.1312 - accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 1s 764us/step - loss: 0.1314 - accuracy: 0.9608\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1308 - accuracy: 0.9613\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 1s 881us/step - loss: 0.1308 - accuracy: 0.9614\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1309 - accuracy: 0.9607\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 1s 843us/step - loss: 0.1305 - accuracy: 0.9616\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 1s 833us/step - loss: 0.1306 - accuracy: 0.9609\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 1s 769us/step - loss: 0.1302 - accuracy: 0.9613\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 1s 892us/step - loss: 0.1305 - accuracy: 0.9625\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.9612\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 1s 884us/step - loss: 0.1296 - accuracy: 0.9621\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 1s 775us/step - loss: 0.1298 - accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 1s 784us/step - loss: 0.1301 - accuracy: 0.9615\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 1s 861us/step - loss: 0.1296 - accuracy: 0.9618\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 1s 790us/step - loss: 0.1288 - accuracy: 0.9609\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 1s 760us/step - loss: 0.1297 - accuracy: 0.9613\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 1s 796us/step - loss: 0.1300 - accuracy: 0.9610\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 1s 759us/step - loss: 0.1293 - accuracy: 0.9619\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 1s 741us/step - loss: 0.1291 - accuracy: 0.9616\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 1s 716us/step - loss: 0.1287 - accuracy: 0.9616\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 1s 722us/step - loss: 0.1294 - accuracy: 0.9609\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 1s 732us/step - loss: 0.1292 - accuracy: 0.9619\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 1s 728us/step - loss: 0.1287 - accuracy: 0.9617\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 1s 735us/step - loss: 0.1288 - accuracy: 0.9619\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 1s 752us/step - loss: 0.1284 - accuracy: 0.9612\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 1s 823us/step - loss: 0.1285 - accuracy: 0.9613\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 1s 817us/step - loss: 0.1286 - accuracy: 0.9612\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 1s 771us/step - loss: 0.1282 - accuracy: 0.9622\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 1s 884us/step - loss: 0.1280 - accuracy: 0.9612\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 1s 900us/step - loss: 0.1285 - accuracy: 0.9612\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 1s 719us/step - loss: 0.1283 - accuracy: 0.9617\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 1s 720us/step - loss: 0.1283 - accuracy: 0.9615\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 1s 721us/step - loss: 0.1281 - accuracy: 0.9616\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 1s 730us/step - loss: 0.1279 - accuracy: 0.9609\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 1s 723us/step - loss: 0.1279 - accuracy: 0.9624\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 1s 737us/step - loss: 0.1280 - accuracy: 0.9616\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 1s 717us/step - loss: 0.1277 - accuracy: 0.9616\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 1s 727us/step - loss: 0.1277 - accuracy: 0.9609\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 1s 718us/step - loss: 0.1283 - accuracy: 0.9613\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 1s 859us/step - loss: 0.1276 - accuracy: 0.9622\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 1s 869us/step - loss: 0.1278 - accuracy: 0.9612\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 1s 863us/step - loss: 0.1276 - accuracy: 0.9615\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 1s 768us/step - loss: 0.1274 - accuracy: 0.9611\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 1s 756us/step - loss: 0.1278 - accuracy: 0.9623\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 1s 819us/step - loss: 0.1278 - accuracy: 0.9617\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 1s 744us/step - loss: 0.1276 - accuracy: 0.9609\n",
      "Epoch 57/100\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.1275 - accuracy: 0.9617\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 1s 770us/step - loss: 0.1271 - accuracy: 0.9616\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1271 - accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 1s 785us/step - loss: 0.1276 - accuracy: 0.9625\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 1s 778us/step - loss: 0.1272 - accuracy: 0.9623\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 1s 758us/step - loss: 0.1270 - accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 1s 765us/step - loss: 0.1277 - accuracy: 0.9613\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 1s 777us/step - loss: 0.1269 - accuracy: 0.9629\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 1s 822us/step - loss: 0.1271 - accuracy: 0.9622\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 1s 786us/step - loss: 0.1269 - accuracy: 0.9620\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 1s 779us/step - loss: 0.1270 - accuracy: 0.9616\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 1s 785us/step - loss: 0.1266 - accuracy: 0.9622\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 1s 770us/step - loss: 0.1265 - accuracy: 0.9619\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 1s 816us/step - loss: 0.1268 - accuracy: 0.9624\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 1s 790us/step - loss: 0.1268 - accuracy: 0.9624\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 1s 774us/step - loss: 0.1266 - accuracy: 0.9613\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 1s 844us/step - loss: 0.1264 - accuracy: 0.9623\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 1s 852us/step - loss: 0.1265 - accuracy: 0.9617\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 1s 865us/step - loss: 0.1265 - accuracy: 0.9620\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 1s 792us/step - loss: 0.1266 - accuracy: 0.9626\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 1s 886us/step - loss: 0.1265 - accuracy: 0.9618\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9623\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 1s 760us/step - loss: 0.1265 - accuracy: 0.9624\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 1s 771us/step - loss: 0.1257 - accuracy: 0.9619\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 1s 771us/step - loss: 0.1261 - accuracy: 0.9622\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 1s 774us/step - loss: 0.1260 - accuracy: 0.9620\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 1s 775us/step - loss: 0.1263 - accuracy: 0.9622\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 1s 738us/step - loss: 0.1258 - accuracy: 0.9618\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 1s 843us/step - loss: 0.1257 - accuracy: 0.9613\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 1s 858us/step - loss: 0.1261 - accuracy: 0.9633\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 1s 850us/step - loss: 0.1252 - accuracy: 0.9611\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 1s 981us/step - loss: 0.1257 - accuracy: 0.9629\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 1s 783us/step - loss: 0.1255 - accuracy: 0.9629\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 1s 791us/step - loss: 0.1259 - accuracy: 0.9618\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 1s 776us/step - loss: 0.1257 - accuracy: 0.9626\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 1s 807us/step - loss: 0.1256 - accuracy: 0.9622\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 1s 780us/step - loss: 0.1250 - accuracy: 0.9623\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 1s 774us/step - loss: 0.1255 - accuracy: 0.9625\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 1s 791us/step - loss: 0.1251 - accuracy: 0.9627\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1250 - accuracy: 0.9625\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 1s 840us/step - loss: 0.1250 - accuracy: 0.9627\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 1s 960us/step - loss: 0.1246 - accuracy: 0.9616\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 1s 810us/step - loss: 0.1246 - accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 2s 2ms/step - loss: 0.1204 - accuracy: 0.9648 - val_loss: 0.1336 - val_accuracy: 0.9587\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1193 - accuracy: 0.9642 - val_loss: 0.1360 - val_accuracy: 0.9594\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1189 - accuracy: 0.9633 - val_loss: 0.1366 - val_accuracy: 0.9578\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.9643 - val_loss: 0.1372 - val_accuracy: 0.9565\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9635 - val_loss: 0.1381 - val_accuracy: 0.9578\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1191 - accuracy: 0.9638 - val_loss: 0.1384 - val_accuracy: 0.9584\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1395 - val_accuracy: 0.9578\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1181 - accuracy: 0.9641 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1404 - val_accuracy: 0.9568\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9642 - val_loss: 0.1404 - val_accuracy: 0.9562\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9642 - val_loss: 0.1400 - val_accuracy: 0.9552\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1415 - val_accuracy: 0.9556\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9642 - val_loss: 0.1410 - val_accuracy: 0.9556\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9646 - val_loss: 0.1412 - val_accuracy: 0.9559\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.9646 - val_loss: 0.1402 - val_accuracy: 0.9559\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1176 - accuracy: 0.9654 - val_loss: 0.1411 - val_accuracy: 0.9543\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1175 - accuracy: 0.9660 - val_loss: 0.1418 - val_accuracy: 0.9549\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9643 - val_loss: 0.1421 - val_accuracy: 0.9552\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9650 - val_loss: 0.1413 - val_accuracy: 0.9543\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.9648 - val_loss: 0.1408 - val_accuracy: 0.9562\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.9641 - val_loss: 0.1424 - val_accuracy: 0.9552\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1415 - val_accuracy: 0.9556\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.9656 - val_loss: 0.1407 - val_accuracy: 0.9562\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1168 - accuracy: 0.9634 - val_loss: 0.1435 - val_accuracy: 0.9556\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9643 - val_loss: 0.1439 - val_accuracy: 0.9527\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1168 - accuracy: 0.9646 - val_loss: 0.1421 - val_accuracy: 0.9552\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.9649 - val_loss: 0.1421 - val_accuracy: 0.9556\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9648 - val_loss: 0.1426 - val_accuracy: 0.9549\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9641 - val_loss: 0.1443 - val_accuracy: 0.9543\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.9657 - val_loss: 0.1423 - val_accuracy: 0.9559\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.9642 - val_loss: 0.1431 - val_accuracy: 0.9546\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.9648 - val_loss: 0.1433 - val_accuracy: 0.9549\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.9648 - val_loss: 0.1431 - val_accuracy: 0.9546\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.9652 - val_loss: 0.1430 - val_accuracy: 0.9552\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.9648 - val_loss: 0.1432 - val_accuracy: 0.9562\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9649 - val_loss: 0.1433 - val_accuracy: 0.9552\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9648 - val_loss: 0.1441 - val_accuracy: 0.9559\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.9653 - val_loss: 0.1440 - val_accuracy: 0.9556\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.9650 - val_loss: 0.1435 - val_accuracy: 0.9562\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1158 - accuracy: 0.9654 - val_loss: 0.1441 - val_accuracy: 0.9549\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9638 - val_loss: 0.1439 - val_accuracy: 0.9556\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9663 - val_loss: 0.1454 - val_accuracy: 0.9530\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9646 - val_loss: 0.1456 - val_accuracy: 0.9543\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1158 - accuracy: 0.9645 - val_loss: 0.1461 - val_accuracy: 0.9556\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9648 - val_loss: 0.1441 - val_accuracy: 0.9546\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.9649 - val_loss: 0.1448 - val_accuracy: 0.9549\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9643 - val_loss: 0.1443 - val_accuracy: 0.9540\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9654 - val_loss: 0.1448 - val_accuracy: 0.9543\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9656 - val_loss: 0.1438 - val_accuracy: 0.9546\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.9646 - val_loss: 0.1442 - val_accuracy: 0.9546\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9658 - val_loss: 0.1444 - val_accuracy: 0.9556\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1154 - accuracy: 0.9650 - val_loss: 0.1447 - val_accuracy: 0.9552\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9649 - val_loss: 0.1438 - val_accuracy: 0.9556\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9642 - val_loss: 0.1449 - val_accuracy: 0.9556\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9665 - val_loss: 0.1439 - val_accuracy: 0.9543\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9649 - val_loss: 0.1435 - val_accuracy: 0.9549\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9650 - val_loss: 0.1456 - val_accuracy: 0.9552\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9658 - val_loss: 0.1448 - val_accuracy: 0.9565\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.1451 - val_accuracy: 0.9549\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9650 - val_loss: 0.1453 - val_accuracy: 0.9549\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9654 - val_loss: 0.1445 - val_accuracy: 0.9562\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.9660 - val_loss: 0.1443 - val_accuracy: 0.9552\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9646 - val_loss: 0.1450 - val_accuracy: 0.9549\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.9652 - val_loss: 0.1462 - val_accuracy: 0.9559\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9657 - val_loss: 0.1456 - val_accuracy: 0.9533\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.9652 - val_loss: 0.1450 - val_accuracy: 0.9537\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9657 - val_loss: 0.1448 - val_accuracy: 0.9543\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9648 - val_loss: 0.1448 - val_accuracy: 0.9533\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9646 - val_loss: 0.1457 - val_accuracy: 0.9527\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9652 - val_loss: 0.1454 - val_accuracy: 0.9530\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9664 - val_loss: 0.1468 - val_accuracy: 0.9543\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.9658 - val_loss: 0.1468 - val_accuracy: 0.9527\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.9657 - val_loss: 0.1458 - val_accuracy: 0.9559\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9654 - val_loss: 0.1453 - val_accuracy: 0.9540\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9657 - val_loss: 0.1452 - val_accuracy: 0.9537\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9660 - val_loss: 0.1461 - val_accuracy: 0.9559\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1133 - accuracy: 0.9654 - val_loss: 0.1463 - val_accuracy: 0.9552\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.9652 - val_loss: 0.1449 - val_accuracy: 0.9543\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9653 - val_loss: 0.1458 - val_accuracy: 0.9556\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.9657 - val_loss: 0.1465 - val_accuracy: 0.9546\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.9652 - val_loss: 0.1458 - val_accuracy: 0.9552\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9663 - val_loss: 0.1458 - val_accuracy: 0.9530\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9658 - val_loss: 0.1459 - val_accuracy: 0.9552\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9653 - val_loss: 0.1454 - val_accuracy: 0.9546\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9648 - val_loss: 0.1468 - val_accuracy: 0.9546\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9652 - val_loss: 0.1461 - val_accuracy: 0.9546\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.1455 - val_accuracy: 0.9543\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9652 - val_loss: 0.1456 - val_accuracy: 0.9533\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9642 - val_loss: 0.1459 - val_accuracy: 0.9540\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9641 - val_loss: 0.1459 - val_accuracy: 0.9537\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.9649 - val_loss: 0.1458 - val_accuracy: 0.9540\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.9648 - val_loss: 0.1457 - val_accuracy: 0.9530\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.1473 - val_accuracy: 0.9546\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.9649 - val_loss: 0.1474 - val_accuracy: 0.9543\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9658 - val_loss: 0.1461 - val_accuracy: 0.9540\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9648 - val_loss: 0.1481 - val_accuracy: 0.9546\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9648 - val_loss: 0.1489 - val_accuracy: 0.9530\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9646 - val_loss: 0.1466 - val_accuracy: 0.9527\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9658 - val_loss: 0.1478 - val_accuracy: 0.9559\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.9656 - val_loss: 0.1446 - val_accuracy: 0.9540\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, validation_split=0.30 ,batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 814us/step - loss: 0.1431 - accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "history = classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 732us/step - loss: 0.1431 - accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "scores = classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.5819 - accuracy: 0.7547 - val_loss: 0.3443 - val_accuracy: 0.8190\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3181 - accuracy: 0.8316 - val_loss: 0.2741 - val_accuracy: 0.8543\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2612 - accuracy: 0.8525 - val_loss: 0.2384 - val_accuracy: 0.8629\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2263 - accuracy: 0.8857 - val_loss: 0.2193 - val_accuracy: 0.9400\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2116 - accuracy: 0.9462 - val_loss: 0.2054 - val_accuracy: 0.9473\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1960 - accuracy: 0.9540 - val_loss: 0.1973 - val_accuracy: 0.9521\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9530 - val_loss: 0.1905 - val_accuracy: 0.9508\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1789 - accuracy: 0.9567 - val_loss: 0.1860 - val_accuracy: 0.9546\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1778 - accuracy: 0.9592 - val_loss: 0.1830 - val_accuracy: 0.9540\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1705 - accuracy: 0.9569 - val_loss: 0.1804 - val_accuracy: 0.9530\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1708 - accuracy: 0.9571 - val_loss: 0.1788 - val_accuracy: 0.9537\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1756 - accuracy: 0.9535 - val_loss: 0.1790 - val_accuracy: 0.9527\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1587 - accuracy: 0.9601 - val_loss: 0.1746 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9576 - val_loss: 0.1743 - val_accuracy: 0.9502\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.9581 - val_loss: 0.1733 - val_accuracy: 0.9505\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1652 - accuracy: 0.9566 - val_loss: 0.1717 - val_accuracy: 0.9505\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1683 - accuracy: 0.9539 - val_loss: 0.1697 - val_accuracy: 0.9524\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1502 - accuracy: 0.9580 - val_loss: 0.1707 - val_accuracy: 0.9505\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9616 - val_loss: 0.1694 - val_accuracy: 0.9498\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1416 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9505\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.9598 - val_loss: 0.1686 - val_accuracy: 0.9505\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1341 - accuracy: 0.9629 - val_loss: 0.1687 - val_accuracy: 0.9486\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1395 - accuracy: 0.9603 - val_loss: 0.1704 - val_accuracy: 0.9489\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1512 - accuracy: 0.9579 - val_loss: 0.1678 - val_accuracy: 0.9495\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1497 - accuracy: 0.9574 - val_loss: 0.1691 - val_accuracy: 0.9479\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1508 - accuracy: 0.9554 - val_loss: 0.1712 - val_accuracy: 0.9489\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1552 - accuracy: 0.9562 - val_loss: 0.1672 - val_accuracy: 0.9514\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9609 - val_loss: 0.1660 - val_accuracy: 0.9502\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.9597 - val_loss: 0.1664 - val_accuracy: 0.9521\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1507 - accuracy: 0.9581 - val_loss: 0.1682 - val_accuracy: 0.9533\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.9543 - val_loss: 0.1662 - val_accuracy: 0.9514\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9604 - val_loss: 0.1672 - val_accuracy: 0.9511\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1455 - accuracy: 0.9608 - val_loss: 0.1668 - val_accuracy: 0.9508\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1459 - accuracy: 0.9597 - val_loss: 0.1686 - val_accuracy: 0.9498\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1461 - accuracy: 0.9566 - val_loss: 0.1663 - val_accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1571 - accuracy: 0.9566 - val_loss: 0.1673 - val_accuracy: 0.9508\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9627 - val_loss: 0.1670 - val_accuracy: 0.9521\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1428 - accuracy: 0.9592 - val_loss: 0.1678 - val_accuracy: 0.9514\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9633 - val_loss: 0.1669 - val_accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1476 - accuracy: 0.9609 - val_loss: 0.1670 - val_accuracy: 0.9530\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1394 - accuracy: 0.9610 - val_loss: 0.1645 - val_accuracy: 0.9527\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1439 - accuracy: 0.9605 - val_loss: 0.1652 - val_accuracy: 0.9521\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9578 - val_loss: 0.1654 - val_accuracy: 0.9517\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1347 - accuracy: 0.9610 - val_loss: 0.1651 - val_accuracy: 0.9521\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1493 - accuracy: 0.9553 - val_loss: 0.1653 - val_accuracy: 0.9521\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1439 - accuracy: 0.9578 - val_loss: 0.1645 - val_accuracy: 0.9537\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1587 - accuracy: 0.9573 - val_loss: 0.1640 - val_accuracy: 0.9521\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9568 - val_loss: 0.1657 - val_accuracy: 0.9533\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1394 - accuracy: 0.9638 - val_loss: 0.1646 - val_accuracy: 0.9540\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1341 - accuracy: 0.9631 - val_loss: 0.1644 - val_accuracy: 0.9533\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.9610 - val_loss: 0.1654 - val_accuracy: 0.9521\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9656 - val_loss: 0.1628 - val_accuracy: 0.9527\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9636 - val_loss: 0.1643 - val_accuracy: 0.9517\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9626 - val_loss: 0.1637 - val_accuracy: 0.9521\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1521 - accuracy: 0.9590 - val_loss: 0.1641 - val_accuracy: 0.9527\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1348 - accuracy: 0.9630 - val_loss: 0.1629 - val_accuracy: 0.9521\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1419 - accuracy: 0.9593 - val_loss: 0.1634 - val_accuracy: 0.9517\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9581 - val_loss: 0.1622 - val_accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1574 - accuracy: 0.9566 - val_loss: 0.1613 - val_accuracy: 0.9540\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1505 - accuracy: 0.9613 - val_loss: 0.1629 - val_accuracy: 0.9540\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.9623 - val_loss: 0.1636 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9590 - val_loss: 0.1635 - val_accuracy: 0.9543\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.9623 - val_loss: 0.1626 - val_accuracy: 0.9537\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1363 - accuracy: 0.9616 - val_loss: 0.1622 - val_accuracy: 0.9530\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1332 - accuracy: 0.9635 - val_loss: 0.1621 - val_accuracy: 0.9537\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1321 - accuracy: 0.9633 - val_loss: 0.1626 - val_accuracy: 0.9508\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.9624 - val_loss: 0.1627 - val_accuracy: 0.9511\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1408 - accuracy: 0.9600 - val_loss: 0.1633 - val_accuracy: 0.9537\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1455 - accuracy: 0.9590 - val_loss: 0.1645 - val_accuracy: 0.9537\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1321 - accuracy: 0.9636 - val_loss: 0.1625 - val_accuracy: 0.9543\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9616 - val_loss: 0.1621 - val_accuracy: 0.9537\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1261 - accuracy: 0.9614 - val_loss: 0.1631 - val_accuracy: 0.9527\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.9643 - val_loss: 0.1633 - val_accuracy: 0.9517\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.9585 - val_loss: 0.1625 - val_accuracy: 0.9546\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1427 - accuracy: 0.9609 - val_loss: 0.1621 - val_accuracy: 0.9521\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.1610 - val_accuracy: 0.9540\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.9639 - val_loss: 0.1616 - val_accuracy: 0.9530\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1319 - accuracy: 0.9616 - val_loss: 0.1619 - val_accuracy: 0.9549\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1476 - accuracy: 0.9582 - val_loss: 0.1611 - val_accuracy: 0.9546\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9591 - val_loss: 0.1638 - val_accuracy: 0.9571\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.9621 - val_loss: 0.1606 - val_accuracy: 0.9517\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1425 - accuracy: 0.9571 - val_loss: 0.1620 - val_accuracy: 0.9540\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1328 - accuracy: 0.9633 - val_loss: 0.1611 - val_accuracy: 0.9521\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1472 - accuracy: 0.9584 - val_loss: 0.1607 - val_accuracy: 0.9524\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9616 - val_loss: 0.1612 - val_accuracy: 0.9537\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9625 - val_loss: 0.1600 - val_accuracy: 0.9530\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.9605 - val_loss: 0.1608 - val_accuracy: 0.9527\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1337 - accuracy: 0.9604 - val_loss: 0.1593 - val_accuracy: 0.9517\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1423 - accuracy: 0.9583 - val_loss: 0.1613 - val_accuracy: 0.9543\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1422 - accuracy: 0.9605 - val_loss: 0.1600 - val_accuracy: 0.9537\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1339 - accuracy: 0.9607 - val_loss: 0.1616 - val_accuracy: 0.9533\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1318 - accuracy: 0.9613 - val_loss: 0.1607 - val_accuracy: 0.9543\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1433 - accuracy: 0.9567 - val_loss: 0.1617 - val_accuracy: 0.9521\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9600 - val_loss: 0.1612 - val_accuracy: 0.9524\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9632 - val_loss: 0.1594 - val_accuracy: 0.9540\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1328 - accuracy: 0.9622 - val_loss: 0.1596 - val_accuracy: 0.9540\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9602 - val_loss: 0.1595 - val_accuracy: 0.9549\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.9649 - val_loss: 0.1595 - val_accuracy: 0.9533\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9624 - val_loss: 0.1585 - val_accuracy: 0.9559\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9599 - val_loss: 0.1595 - val_accuracy: 0.9543\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "model.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.30 ,batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 95.31% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import numpy as np # linear algebra\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 2s 2ms/step - loss: 0.5894 - accuracy: 0.7566 - val_loss: 0.3359 - val_accuracy: 0.8190\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2993 - accuracy: 0.8605 - val_loss: 0.2248 - val_accuracy: 0.9283\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9382 - val_loss: 0.1853 - val_accuracy: 0.9454\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1618 - accuracy: 0.9506 - val_loss: 0.1700 - val_accuracy: 0.9492\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9563 - val_loss: 0.1641 - val_accuracy: 0.9508\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.9596 - val_loss: 0.1588 - val_accuracy: 0.9568\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9575 - val_loss: 0.1573 - val_accuracy: 0.9552\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.9617 - val_loss: 0.1593 - val_accuracy: 0.9552\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1334 - accuracy: 0.9630 - val_loss: 0.1562 - val_accuracy: 0.9537\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.9619 - val_loss: 0.1557 - val_accuracy: 0.9546\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9631 - val_loss: 0.1527 - val_accuracy: 0.9559\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.9662 - val_loss: 0.1552 - val_accuracy: 0.9546\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1388 - accuracy: 0.9630 - val_loss: 0.1539 - val_accuracy: 0.9565\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9657 - val_loss: 0.1512 - val_accuracy: 0.9571\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1282 - accuracy: 0.9657 - val_loss: 0.1558 - val_accuracy: 0.9530\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1302 - accuracy: 0.9637 - val_loss: 0.1502 - val_accuracy: 0.9562\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1257 - accuracy: 0.9652 - val_loss: 0.1508 - val_accuracy: 0.9559\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1224 - accuracy: 0.9659 - val_loss: 0.1525 - val_accuracy: 0.9562\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1208 - accuracy: 0.9675 - val_loss: 0.1503 - val_accuracy: 0.9568\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9658 - val_loss: 0.1500 - val_accuracy: 0.9571\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1226 - accuracy: 0.9671 - val_loss: 0.1502 - val_accuracy: 0.9575\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.9697 - val_loss: 0.1489 - val_accuracy: 0.9568\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9664 - val_loss: 0.1497 - val_accuracy: 0.9546\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1325 - accuracy: 0.9653 - val_loss: 0.1486 - val_accuracy: 0.9568\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1160 - accuracy: 0.9712 - val_loss: 0.1470 - val_accuracy: 0.9575\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9650 - val_loss: 0.1494 - val_accuracy: 0.9571\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1096 - accuracy: 0.9707 - val_loss: 0.1475 - val_accuracy: 0.9571\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9709 - val_loss: 0.1482 - val_accuracy: 0.9562\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: 0.1528 - val_accuracy: 0.9527\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9686 - val_loss: 0.1509 - val_accuracy: 0.9543\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.9685 - val_loss: 0.1462 - val_accuracy: 0.9584\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1157 - accuracy: 0.9678 - val_loss: 0.1450 - val_accuracy: 0.9590\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9716 - val_loss: 0.1502 - val_accuracy: 0.9581\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.9679 - val_loss: 0.1438 - val_accuracy: 0.9581\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1267 - accuracy: 0.9665 - val_loss: 0.1451 - val_accuracy: 0.9584\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1258 - accuracy: 0.9653 - val_loss: 0.1469 - val_accuracy: 0.9568\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.9726 - val_loss: 0.1604 - val_accuracy: 0.9508\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9758 - val_loss: 0.1548 - val_accuracy: 0.9578\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9688 - val_loss: 0.1425 - val_accuracy: 0.9581\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.9703 - val_loss: 0.1427 - val_accuracy: 0.9584\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9689 - val_loss: 0.1445 - val_accuracy: 0.9590\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9736 - val_loss: 0.1461 - val_accuracy: 0.9575\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9745 - val_loss: 0.1425 - val_accuracy: 0.9587\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9679 - val_loss: 0.1464 - val_accuracy: 0.9565\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.9677 - val_loss: 0.1446 - val_accuracy: 0.9590\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1231 - accuracy: 0.9671 - val_loss: 0.1473 - val_accuracy: 0.9590\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9705 - val_loss: 0.1423 - val_accuracy: 0.9578\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.9723 - val_loss: 0.1470 - val_accuracy: 0.9571\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9690 - val_loss: 0.1465 - val_accuracy: 0.9594\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.9687 - val_loss: 0.1504 - val_accuracy: 0.9584\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9717 - val_loss: 0.1406 - val_accuracy: 0.9603\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9740 - val_loss: 0.1505 - val_accuracy: 0.9562\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9691 - val_loss: 0.1436 - val_accuracy: 0.9578\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9688 - val_loss: 0.1423 - val_accuracy: 0.9581\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9703 - val_loss: 0.1427 - val_accuracy: 0.9587\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9703 - val_loss: 0.1413 - val_accuracy: 0.9587\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.9709 - val_loss: 0.1454 - val_accuracy: 0.9581\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9673 - val_loss: 0.1448 - val_accuracy: 0.9581\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9680 - val_loss: 0.1420 - val_accuracy: 0.9587\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9732 - val_loss: 0.1435 - val_accuracy: 0.9590\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9753 - val_loss: 0.1478 - val_accuracy: 0.9562\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.9722 - val_loss: 0.1428 - val_accuracy: 0.9568\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.1464 - val_accuracy: 0.9587\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9705 - val_loss: 0.1416 - val_accuracy: 0.9581\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9723 - val_loss: 0.1434 - val_accuracy: 0.9594\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1050 - accuracy: 0.9721 - val_loss: 0.1410 - val_accuracy: 0.9581\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.9722 - val_loss: 0.1405 - val_accuracy: 0.9587\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9717 - val_loss: 0.1422 - val_accuracy: 0.9587\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.9700 - val_loss: 0.1440 - val_accuracy: 0.9590\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.9706 - val_loss: 0.1415 - val_accuracy: 0.9581\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.9704 - val_loss: 0.1456 - val_accuracy: 0.9584\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.9711 - val_loss: 0.1471 - val_accuracy: 0.9571\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9738 - val_loss: 0.1470 - val_accuracy: 0.9581\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.9689 - val_loss: 0.1466 - val_accuracy: 0.9578\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9761 - val_loss: 0.1426 - val_accuracy: 0.9578\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9727 - val_loss: 0.1443 - val_accuracy: 0.9584\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9752 - val_loss: 0.1447 - val_accuracy: 0.9575\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9739 - val_loss: 0.1430 - val_accuracy: 0.9565\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9691 - val_loss: 0.1449 - val_accuracy: 0.9581\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9689 - val_loss: 0.1494 - val_accuracy: 0.9556\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9697 - val_loss: 0.1461 - val_accuracy: 0.9571\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.9706 - val_loss: 0.1448 - val_accuracy: 0.9578\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9712 - val_loss: 0.1602 - val_accuracy: 0.9517\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.1429 - val_accuracy: 0.9584\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9744 - val_loss: 0.1473 - val_accuracy: 0.9571\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9724 - val_loss: 0.1413 - val_accuracy: 0.9587\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9741 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1157 - accuracy: 0.9689 - val_loss: 0.1475 - val_accuracy: 0.9578\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.9710 - val_loss: 0.1438 - val_accuracy: 0.9584\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9712 - val_loss: 0.1434 - val_accuracy: 0.9578\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9741 - val_loss: 0.1405 - val_accuracy: 0.9587\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9700 - val_loss: 0.1417 - val_accuracy: 0.9600\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9737 - val_loss: 0.1457 - val_accuracy: 0.9578\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.1417 - val_accuracy: 0.9594\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9672 - val_loss: 0.1446 - val_accuracy: 0.9578\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9696 - val_loss: 0.1458 - val_accuracy: 0.9578\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9735 - val_loss: 0.1422 - val_accuracy: 0.9587\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9718 - val_loss: 0.1420 - val_accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9740 - val_loss: 0.1420 - val_accuracy: 0.9590\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9736 - val_loss: 0.1468 - val_accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "model.add(Dense(5, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "model.add(Dense(3, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "model.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.30 ,batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9591\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 95.91% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Regularization Hyperparameter\n",
    "Once you can confirm that weight regularization may improve your overfit model, you can test different values of the regularization parameter.\n",
    "\n",
    "It is a good practice to first grid search through some orders of magnitude between 0.0 and 0.1, then once a level is found, to grid search on that level.\n",
    "\n",
    "We can grid search through the orders of magnitude by defining the values to test, looping through each and recording the train and test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.7542 - val_loss: 0.3767 - val_accuracy: 0.7632\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.7825 - val_loss: 0.3210 - val_accuracy: 0.8673\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3103 - accuracy: 0.8764 - val_loss: 0.2861 - val_accuracy: 0.8968\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2768 - accuracy: 0.9083 - val_loss: 0.2679 - val_accuracy: 0.9146\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.9185 - val_loss: 0.2527 - val_accuracy: 0.9194\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.9275 - val_loss: 0.2423 - val_accuracy: 0.9222\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2218 - accuracy: 0.9384 - val_loss: 0.2366 - val_accuracy: 0.9241\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9304 - val_loss: 0.2268 - val_accuracy: 0.9283\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2129 - accuracy: 0.9358 - val_loss: 0.2228 - val_accuracy: 0.9260\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.2030 - accuracy: 0.9416 - val_loss: 0.2187 - val_accuracy: 0.9289\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2027 - accuracy: 0.9397 - val_loss: 0.2161 - val_accuracy: 0.9298\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2041 - accuracy: 0.9388 - val_loss: 0.2127 - val_accuracy: 0.9305\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2052 - accuracy: 0.9359 - val_loss: 0.2135 - val_accuracy: 0.9330\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1860 - accuracy: 0.9445 - val_loss: 0.2106 - val_accuracy: 0.9289\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1836 - accuracy: 0.9435 - val_loss: 0.2090 - val_accuracy: 0.9349\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1944 - accuracy: 0.9434 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1902 - accuracy: 0.9433 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9440 - val_loss: 0.2056 - val_accuracy: 0.9356\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1891 - accuracy: 0.9403 - val_loss: 0.2045 - val_accuracy: 0.9321\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2001 - accuracy: 0.9391 - val_loss: 0.2045 - val_accuracy: 0.9365\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1769 - accuracy: 0.9477 - val_loss: 0.2021 - val_accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1893 - accuracy: 0.9458 - val_loss: 0.2032 - val_accuracy: 0.9390\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1931 - accuracy: 0.9438 - val_loss: 0.2015 - val_accuracy: 0.9362\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1929 - accuracy: 0.9444 - val_loss: 0.2008 - val_accuracy: 0.9362\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1894 - accuracy: 0.9446 - val_loss: 0.2023 - val_accuracy: 0.9356\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1862 - accuracy: 0.9447 - val_loss: 0.2019 - val_accuracy: 0.9368\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1878 - accuracy: 0.9481 - val_loss: 0.2021 - val_accuracy: 0.9362\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9418 - val_loss: 0.2000 - val_accuracy: 0.9359\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1852 - accuracy: 0.9454 - val_loss: 0.2002 - val_accuracy: 0.9333\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1869 - accuracy: 0.9434 - val_loss: 0.2014 - val_accuracy: 0.9384\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1989 - accuracy: 0.9444 - val_loss: 0.1996 - val_accuracy: 0.9371\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1782 - accuracy: 0.9485 - val_loss: 0.2013 - val_accuracy: 0.9321\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1941 - accuracy: 0.9425 - val_loss: 0.2007 - val_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1807 - accuracy: 0.9481 - val_loss: 0.1995 - val_accuracy: 0.9359\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1870 - accuracy: 0.9462 - val_loss: 0.1991 - val_accuracy: 0.9343\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9521 - val_loss: 0.1994 - val_accuracy: 0.9362\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1877 - accuracy: 0.9493 - val_loss: 0.2010 - val_accuracy: 0.9387\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1816 - accuracy: 0.9483 - val_loss: 0.1993 - val_accuracy: 0.9362\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1961 - accuracy: 0.9424 - val_loss: 0.2001 - val_accuracy: 0.9371\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9520 - val_loss: 0.1989 - val_accuracy: 0.9365\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1815 - accuracy: 0.9472 - val_loss: 0.1994 - val_accuracy: 0.9362\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1754 - accuracy: 0.9524 - val_loss: 0.1998 - val_accuracy: 0.9371\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1838 - accuracy: 0.9475 - val_loss: 0.1988 - val_accuracy: 0.9362\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1728 - accuracy: 0.9496 - val_loss: 0.1998 - val_accuracy: 0.9375\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1797 - accuracy: 0.9471 - val_loss: 0.2008 - val_accuracy: 0.9365\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.9433 - val_loss: 0.2005 - val_accuracy: 0.9378\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1825 - accuracy: 0.9488 - val_loss: 0.2014 - val_accuracy: 0.9387\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1794 - accuracy: 0.9499 - val_loss: 0.1990 - val_accuracy: 0.9365\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1688 - accuracy: 0.9472 - val_loss: 0.1991 - val_accuracy: 0.9343\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1691 - accuracy: 0.9487 - val_loss: 0.2013 - val_accuracy: 0.9343\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1817 - accuracy: 0.9460 - val_loss: 0.2008 - val_accuracy: 0.9410\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1770 - accuracy: 0.9491 - val_loss: 0.1994 - val_accuracy: 0.9400\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1877 - accuracy: 0.9489 - val_loss: 0.1995 - val_accuracy: 0.9362\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1802 - accuracy: 0.9490 - val_loss: 0.2008 - val_accuracy: 0.9390\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1829 - accuracy: 0.9496 - val_loss: 0.1990 - val_accuracy: 0.9387\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9491 - val_loss: 0.2007 - val_accuracy: 0.9321\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1663 - accuracy: 0.9524 - val_loss: 0.1984 - val_accuracy: 0.9387\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1567 - accuracy: 0.9523 - val_loss: 0.1996 - val_accuracy: 0.9368\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9469 - val_loss: 0.1994 - val_accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1741 - accuracy: 0.9496 - val_loss: 0.1984 - val_accuracy: 0.9371\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9502 - val_loss: 0.1997 - val_accuracy: 0.9378\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.9477 - val_loss: 0.1991 - val_accuracy: 0.9381\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1893 - accuracy: 0.9463 - val_loss: 0.2000 - val_accuracy: 0.9381\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1977 - accuracy: 0.9445 - val_loss: 0.2013 - val_accuracy: 0.9413\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1785 - accuracy: 0.9501 - val_loss: 0.1990 - val_accuracy: 0.9390\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9507 - val_loss: 0.1989 - val_accuracy: 0.9346\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9491 - val_loss: 0.2000 - val_accuracy: 0.9413\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1922 - accuracy: 0.9465 - val_loss: 0.1985 - val_accuracy: 0.9368\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1688 - accuracy: 0.9494 - val_loss: 0.1980 - val_accuracy: 0.9368\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1930 - accuracy: 0.9451 - val_loss: 0.2006 - val_accuracy: 0.9413\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1704 - accuracy: 0.9516 - val_loss: 0.1989 - val_accuracy: 0.9406\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1875 - accuracy: 0.9480 - val_loss: 0.1998 - val_accuracy: 0.9387\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1739 - accuracy: 0.9485 - val_loss: 0.1996 - val_accuracy: 0.9381\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9488 - val_loss: 0.1996 - val_accuracy: 0.9410\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1922 - accuracy: 0.9460 - val_loss: 0.1984 - val_accuracy: 0.9381\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9463 - val_loss: 0.2005 - val_accuracy: 0.9403\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1855 - accuracy: 0.9470 - val_loss: 0.1991 - val_accuracy: 0.9390\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1782 - accuracy: 0.9500 - val_loss: 0.1986 - val_accuracy: 0.9390\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1608 - accuracy: 0.9532 - val_loss: 0.1994 - val_accuracy: 0.9387\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1830 - accuracy: 0.9464 - val_loss: 0.1988 - val_accuracy: 0.9365\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9434 - val_loss: 0.1990 - val_accuracy: 0.9384\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1689 - accuracy: 0.9506 - val_loss: 0.1979 - val_accuracy: 0.9365\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1677 - accuracy: 0.9481 - val_loss: 0.1983 - val_accuracy: 0.9343\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9518 - val_loss: 0.1987 - val_accuracy: 0.9378\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1882 - accuracy: 0.9448 - val_loss: 0.1973 - val_accuracy: 0.9371\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1720 - accuracy: 0.9522 - val_loss: 0.1979 - val_accuracy: 0.9359\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1835 - accuracy: 0.9465 - val_loss: 0.1978 - val_accuracy: 0.9365\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1809 - accuracy: 0.9452 - val_loss: 0.1986 - val_accuracy: 0.9397\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1642 - accuracy: 0.9529 - val_loss: 0.1986 - val_accuracy: 0.9368\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1873 - accuracy: 0.9473 - val_loss: 0.1997 - val_accuracy: 0.9413\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1805 - accuracy: 0.9497 - val_loss: 0.1983 - val_accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1815 - accuracy: 0.9507 - val_loss: 0.2011 - val_accuracy: 0.9410\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9482 - val_loss: 0.1989 - val_accuracy: 0.9384\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9486 - val_loss: 0.1976 - val_accuracy: 0.9371\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9488 - val_loss: 0.1979 - val_accuracy: 0.9343\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9522 - val_loss: 0.1971 - val_accuracy: 0.9365\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1836 - accuracy: 0.9448 - val_loss: 0.1974 - val_accuracy: 0.9371\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1854 - accuracy: 0.9499 - val_loss: 0.1981 - val_accuracy: 0.9346\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1728 - accuracy: 0.9477 - val_loss: 0.1978 - val_accuracy: 0.9352\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9462 - val_loss: 0.1994 - val_accuracy: 0.9406\n",
      "Param: 0.100000, Train: 0.949, Test: 0.943\n",
      "Epoch 1/100\n",
      "735/735 [==============================] - 2s 1ms/step - loss: 0.5584 - accuracy: 0.7672 - val_loss: 0.3531 - val_accuracy: 0.7632\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3380 - accuracy: 0.8280 - val_loss: 0.2918 - val_accuracy: 0.9038\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2859 - accuracy: 0.9085 - val_loss: 0.2662 - val_accuracy: 0.9137\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2564 - accuracy: 0.9255 - val_loss: 0.2497 - val_accuracy: 0.9270\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9301 - val_loss: 0.2375 - val_accuracy: 0.9263\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2147 - accuracy: 0.9395 - val_loss: 0.2298 - val_accuracy: 0.9241\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2119 - accuracy: 0.9380 - val_loss: 0.2241 - val_accuracy: 0.9270\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2108 - accuracy: 0.9377 - val_loss: 0.2203 - val_accuracy: 0.9340\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2135 - accuracy: 0.9327 - val_loss: 0.2156 - val_accuracy: 0.9317\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1977 - accuracy: 0.9439 - val_loss: 0.2120 - val_accuracy: 0.9321\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2021 - accuracy: 0.9372 - val_loss: 0.2105 - val_accuracy: 0.9327\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2003 - accuracy: 0.9396 - val_loss: 0.2123 - val_accuracy: 0.9343\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.9439 - val_loss: 0.2073 - val_accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9386 - val_loss: 0.2091 - val_accuracy: 0.9327\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9436 - val_loss: 0.2064 - val_accuracy: 0.9298\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1889 - accuracy: 0.9434 - val_loss: 0.2064 - val_accuracy: 0.9330\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1881 - accuracy: 0.9439 - val_loss: 0.2070 - val_accuracy: 0.9330\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9436 - val_loss: 0.2080 - val_accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1803 - accuracy: 0.9456 - val_loss: 0.2063 - val_accuracy: 0.9330\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1832 - accuracy: 0.9429 - val_loss: 0.2045 - val_accuracy: 0.9295\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1777 - accuracy: 0.9468 - val_loss: 0.2068 - val_accuracy: 0.9302\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1871 - accuracy: 0.9391 - val_loss: 0.2052 - val_accuracy: 0.9362\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.9399 - val_loss: 0.2050 - val_accuracy: 0.9311\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.9414 - val_loss: 0.2052 - val_accuracy: 0.9337\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1931 - accuracy: 0.9456 - val_loss: 0.2055 - val_accuracy: 0.9337\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1985 - accuracy: 0.9385 - val_loss: 0.2059 - val_accuracy: 0.9352\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1905 - accuracy: 0.9444 - val_loss: 0.2055 - val_accuracy: 0.9327\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9427 - val_loss: 0.2051 - val_accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1863 - accuracy: 0.9467 - val_loss: 0.2031 - val_accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1883 - accuracy: 0.9468 - val_loss: 0.2032 - val_accuracy: 0.9349\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1804 - accuracy: 0.9469 - val_loss: 0.2039 - val_accuracy: 0.9368\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1714 - accuracy: 0.9510 - val_loss: 0.2037 - val_accuracy: 0.9340\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1845 - accuracy: 0.9477 - val_loss: 0.2025 - val_accuracy: 0.9359\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1825 - accuracy: 0.9499 - val_loss: 0.2064 - val_accuracy: 0.9365\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9472 - val_loss: 0.2030 - val_accuracy: 0.9343\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1961 - accuracy: 0.9442 - val_loss: 0.2028 - val_accuracy: 0.9327\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1796 - accuracy: 0.9468 - val_loss: 0.2050 - val_accuracy: 0.9295\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1843 - accuracy: 0.9441 - val_loss: 0.2041 - val_accuracy: 0.9362\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1944 - accuracy: 0.9419 - val_loss: 0.2038 - val_accuracy: 0.9384\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1752 - accuracy: 0.9488 - val_loss: 0.2043 - val_accuracy: 0.9362\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9461 - val_loss: 0.2039 - val_accuracy: 0.9343\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1808 - accuracy: 0.9497 - val_loss: 0.2037 - val_accuracy: 0.9349\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1855 - accuracy: 0.9414 - val_loss: 0.2031 - val_accuracy: 0.9333\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9532 - val_loss: 0.2043 - val_accuracy: 0.9352\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9448 - val_loss: 0.2040 - val_accuracy: 0.9359\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1815 - accuracy: 0.9501 - val_loss: 0.2032 - val_accuracy: 0.9337\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1763 - accuracy: 0.9510 - val_loss: 0.2025 - val_accuracy: 0.9343\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9482 - val_loss: 0.2046 - val_accuracy: 0.9352\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1800 - accuracy: 0.9498 - val_loss: 0.2059 - val_accuracy: 0.9375\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9516 - val_loss: 0.2046 - val_accuracy: 0.9324\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1780 - accuracy: 0.9475 - val_loss: 0.2063 - val_accuracy: 0.9343\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9496 - val_loss: 0.2035 - val_accuracy: 0.9356\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9466 - val_loss: 0.2042 - val_accuracy: 0.9340\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1775 - accuracy: 0.9506 - val_loss: 0.2050 - val_accuracy: 0.9362\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1783 - accuracy: 0.9488 - val_loss: 0.2024 - val_accuracy: 0.9346\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1885 - accuracy: 0.9438 - val_loss: 0.2047 - val_accuracy: 0.9337\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1818 - accuracy: 0.9498 - val_loss: 0.2028 - val_accuracy: 0.9349\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1748 - accuracy: 0.9515 - val_loss: 0.2068 - val_accuracy: 0.9346\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1804 - accuracy: 0.9460 - val_loss: 0.2061 - val_accuracy: 0.9387\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1837 - accuracy: 0.9486 - val_loss: 0.2048 - val_accuracy: 0.9349\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9489 - val_loss: 0.2030 - val_accuracy: 0.9314\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1774 - accuracy: 0.9462 - val_loss: 0.2033 - val_accuracy: 0.9340\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1686 - accuracy: 0.9509 - val_loss: 0.2043 - val_accuracy: 0.9302\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1757 - accuracy: 0.9442 - val_loss: 0.2044 - val_accuracy: 0.9394\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9466 - val_loss: 0.2029 - val_accuracy: 0.9349\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1724 - accuracy: 0.9521 - val_loss: 0.2031 - val_accuracy: 0.9384\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9480 - val_loss: 0.2022 - val_accuracy: 0.9359\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1753 - accuracy: 0.9494 - val_loss: 0.2020 - val_accuracy: 0.9368\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1750 - accuracy: 0.9460 - val_loss: 0.2055 - val_accuracy: 0.9295\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9429 - val_loss: 0.2032 - val_accuracy: 0.9368\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1790 - accuracy: 0.9483 - val_loss: 0.2025 - val_accuracy: 0.9352\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1880 - accuracy: 0.9457 - val_loss: 0.2031 - val_accuracy: 0.9397\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1766 - accuracy: 0.9507 - val_loss: 0.2039 - val_accuracy: 0.9365\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9475 - val_loss: 0.2022 - val_accuracy: 0.9390\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1766 - accuracy: 0.9516 - val_loss: 0.2011 - val_accuracy: 0.9384\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1841 - accuracy: 0.9508 - val_loss: 0.2031 - val_accuracy: 0.9362\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1783 - accuracy: 0.9519 - val_loss: 0.2026 - val_accuracy: 0.9346\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.9486 - val_loss: 0.2029 - val_accuracy: 0.9356\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1749 - accuracy: 0.9478 - val_loss: 0.2050 - val_accuracy: 0.9378\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9499 - val_loss: 0.2041 - val_accuracy: 0.9356\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1761 - accuracy: 0.9514 - val_loss: 0.2025 - val_accuracy: 0.9365\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9505 - val_loss: 0.2021 - val_accuracy: 0.9337\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9421 - val_loss: 0.2029 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1832 - accuracy: 0.9437 - val_loss: 0.2026 - val_accuracy: 0.9368\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9506 - val_loss: 0.2028 - val_accuracy: 0.9340\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1835 - accuracy: 0.9468 - val_loss: 0.2031 - val_accuracy: 0.9371\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1662 - accuracy: 0.9488 - val_loss: 0.2032 - val_accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9553 - val_loss: 0.2018 - val_accuracy: 0.9356\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1835 - accuracy: 0.9470 - val_loss: 0.2027 - val_accuracy: 0.9371\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1817 - accuracy: 0.9487 - val_loss: 0.2022 - val_accuracy: 0.9381\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9515 - val_loss: 0.2038 - val_accuracy: 0.9371\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1920 - accuracy: 0.9437 - val_loss: 0.2040 - val_accuracy: 0.9352\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1866 - accuracy: 0.9451 - val_loss: 0.2040 - val_accuracy: 0.9340\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1902 - accuracy: 0.9462 - val_loss: 0.2037 - val_accuracy: 0.9387\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1730 - accuracy: 0.9501 - val_loss: 0.2035 - val_accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9465 - val_loss: 0.2024 - val_accuracy: 0.9340\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1882 - accuracy: 0.9468 - val_loss: 0.2030 - val_accuracy: 0.9365\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1825 - accuracy: 0.9437 - val_loss: 0.2033 - val_accuracy: 0.9346\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9458 - val_loss: 0.2036 - val_accuracy: 0.9378\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1851 - accuracy: 0.9478 - val_loss: 0.2037 - val_accuracy: 0.9349\n",
      "Param: 0.010000, Train: 0.944, Test: 0.940\n",
      "Epoch 1/100\n",
      "735/735 [==============================] - 2s 1ms/step - loss: 0.5852 - accuracy: 0.7610 - val_loss: 0.3517 - val_accuracy: 0.7632\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.7738 - val_loss: 0.2646 - val_accuracy: 0.9302\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2586 - accuracy: 0.9337 - val_loss: 0.2277 - val_accuracy: 0.9438\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2131 - accuracy: 0.9507 - val_loss: 0.2073 - val_accuracy: 0.9483\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1817 - accuracy: 0.9552 - val_loss: 0.1951 - val_accuracy: 0.9521\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.9529 - val_loss: 0.1857 - val_accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1644 - accuracy: 0.9578 - val_loss: 0.1782 - val_accuracy: 0.9521\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1589 - accuracy: 0.9578 - val_loss: 0.1722 - val_accuracy: 0.9521\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1692 - accuracy: 0.9535 - val_loss: 0.1692 - val_accuracy: 0.9527\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1553 - accuracy: 0.9594 - val_loss: 0.1670 - val_accuracy: 0.9556\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1428 - accuracy: 0.9621 - val_loss: 0.1662 - val_accuracy: 0.9527\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1543 - accuracy: 0.9554 - val_loss: 0.1649 - val_accuracy: 0.9549\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1466 - accuracy: 0.9583 - val_loss: 0.1630 - val_accuracy: 0.9556\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9659 - val_loss: 0.1624 - val_accuracy: 0.9498\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1435 - accuracy: 0.9592 - val_loss: 0.1625 - val_accuracy: 0.9540\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9637 - val_loss: 0.1582 - val_accuracy: 0.9546\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.9646 - val_loss: 0.1584 - val_accuracy: 0.9527\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1380 - accuracy: 0.9585 - val_loss: 0.1595 - val_accuracy: 0.9543\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.9635 - val_loss: 0.1596 - val_accuracy: 0.9559\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9625 - val_loss: 0.1587 - val_accuracy: 0.9540\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1299 - accuracy: 0.9621 - val_loss: 0.1565 - val_accuracy: 0.9546\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.9631 - val_loss: 0.1590 - val_accuracy: 0.9556\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9636 - val_loss: 0.1562 - val_accuracy: 0.9540\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1269 - accuracy: 0.9658 - val_loss: 0.1569 - val_accuracy: 0.9556\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1294 - accuracy: 0.9644 - val_loss: 0.1605 - val_accuracy: 0.9552\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.9663 - val_loss: 0.1576 - val_accuracy: 0.9514\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9633 - val_loss: 0.1559 - val_accuracy: 0.9521\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9652 - val_loss: 0.1581 - val_accuracy: 0.9511\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9657 - val_loss: 0.1563 - val_accuracy: 0.9524\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.9651 - val_loss: 0.1578 - val_accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9632 - val_loss: 0.1555 - val_accuracy: 0.9546\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1331 - accuracy: 0.9594 - val_loss: 0.1550 - val_accuracy: 0.9540\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1310 - accuracy: 0.9619 - val_loss: 0.1565 - val_accuracy: 0.9517\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1255 - accuracy: 0.9636 - val_loss: 0.1572 - val_accuracy: 0.9530\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.9627 - val_loss: 0.1546 - val_accuracy: 0.9556\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9676 - val_loss: 0.1535 - val_accuracy: 0.9530\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.9636 - val_loss: 0.1557 - val_accuracy: 0.9549\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9634 - val_loss: 0.1533 - val_accuracy: 0.9530\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9613 - val_loss: 0.1536 - val_accuracy: 0.9543\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9648 - val_loss: 0.1530 - val_accuracy: 0.9537\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1277 - accuracy: 0.9615 - val_loss: 0.1576 - val_accuracy: 0.9559\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.9635 - val_loss: 0.1527 - val_accuracy: 0.9543\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.9633 - val_loss: 0.1551 - val_accuracy: 0.9549\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9631 - val_loss: 0.1521 - val_accuracy: 0.9533\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.9678 - val_loss: 0.1525 - val_accuracy: 0.9552\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1172 - accuracy: 0.9627 - val_loss: 0.1524 - val_accuracy: 0.9546\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1234 - accuracy: 0.9633 - val_loss: 0.1532 - val_accuracy: 0.9540\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.1526 - val_accuracy: 0.9527\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9638 - val_loss: 0.1520 - val_accuracy: 0.9533\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.9632 - val_loss: 0.1504 - val_accuracy: 0.9527\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9672 - val_loss: 0.1533 - val_accuracy: 0.9546\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9634 - val_loss: 0.1509 - val_accuracy: 0.9530\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9659 - val_loss: 0.1502 - val_accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9657 - val_loss: 0.1522 - val_accuracy: 0.9540\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1181 - accuracy: 0.9629 - val_loss: 0.1522 - val_accuracy: 0.9521\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9663 - val_loss: 0.1540 - val_accuracy: 0.9549\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1091 - accuracy: 0.9678 - val_loss: 0.1500 - val_accuracy: 0.9537\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.9686 - val_loss: 0.1508 - val_accuracy: 0.9530\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.9689 - val_loss: 0.1503 - val_accuracy: 0.9546\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9708 - val_loss: 0.1540 - val_accuracy: 0.9521\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9650 - val_loss: 0.1505 - val_accuracy: 0.9530\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.1544 - val_accuracy: 0.9514\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9668 - val_loss: 0.1493 - val_accuracy: 0.9533\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.9660 - val_loss: 0.1534 - val_accuracy: 0.9511\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.9627 - val_loss: 0.1584 - val_accuracy: 0.9537\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9691 - val_loss: 0.1573 - val_accuracy: 0.9530\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9641 - val_loss: 0.1542 - val_accuracy: 0.9540\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.9666 - val_loss: 0.1526 - val_accuracy: 0.9530\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9648 - val_loss: 0.1577 - val_accuracy: 0.9486\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.1514 - val_accuracy: 0.9537\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9687 - val_loss: 0.1543 - val_accuracy: 0.9549\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9685 - val_loss: 0.1519 - val_accuracy: 0.9527\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.9614 - val_loss: 0.1544 - val_accuracy: 0.9533\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.1539 - val_accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1045 - accuracy: 0.9659 - val_loss: 0.1534 - val_accuracy: 0.9540\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9670 - val_loss: 0.1498 - val_accuracy: 0.9527\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9688 - val_loss: 0.1510 - val_accuracy: 0.9540\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9672 - val_loss: 0.1551 - val_accuracy: 0.9537\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9674 - val_loss: 0.1525 - val_accuracy: 0.9514\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9629 - val_loss: 0.1518 - val_accuracy: 0.9533\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9651 - val_loss: 0.1530 - val_accuracy: 0.9517\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9622 - val_loss: 0.1509 - val_accuracy: 0.9530\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9640 - val_loss: 0.1548 - val_accuracy: 0.9537\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9638 - val_loss: 0.1527 - val_accuracy: 0.9540\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9666 - val_loss: 0.1539 - val_accuracy: 0.9537\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9660 - val_loss: 0.1536 - val_accuracy: 0.9533\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.9650 - val_loss: 0.1543 - val_accuracy: 0.9537\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9680 - val_loss: 0.1559 - val_accuracy: 0.9514\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9704 - val_loss: 0.1536 - val_accuracy: 0.9537\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1050 - accuracy: 0.9656 - val_loss: 0.1524 - val_accuracy: 0.9549\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.9653 - val_loss: 0.1521 - val_accuracy: 0.9537\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9673 - val_loss: 0.1529 - val_accuracy: 0.9540\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9679 - val_loss: 0.1524 - val_accuracy: 0.9549\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9688 - val_loss: 0.1529 - val_accuracy: 0.9559\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9673 - val_loss: 0.1519 - val_accuracy: 0.9568\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1119 - accuracy: 0.9670 - val_loss: 0.1504 - val_accuracy: 0.9546\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9674 - val_loss: 0.1524 - val_accuracy: 0.9546\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9670 - val_loss: 0.1560 - val_accuracy: 0.9552\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9670 - val_loss: 0.1518 - val_accuracy: 0.9546\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9659 - val_loss: 0.1523 - val_accuracy: 0.9543\n",
      "Param: 0.001000, Train: 0.963, Test: 0.957\n",
      "Epoch 1/100\n",
      "735/735 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.7633 - val_loss: 0.3565 - val_accuracy: 0.7632\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.3405 - accuracy: 0.8236 - val_loss: 0.3006 - val_accuracy: 0.8851\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2888 - accuracy: 0.8995 - val_loss: 0.2679 - val_accuracy: 0.9133\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2556 - accuracy: 0.9229 - val_loss: 0.2490 - val_accuracy: 0.9219\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2387 - accuracy: 0.9278 - val_loss: 0.2352 - val_accuracy: 0.9248\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2163 - accuracy: 0.9384 - val_loss: 0.2247 - val_accuracy: 0.9308\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2129 - accuracy: 0.9398 - val_loss: 0.2166 - val_accuracy: 0.9305\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2052 - accuracy: 0.9436 - val_loss: 0.2123 - val_accuracy: 0.9321\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1986 - accuracy: 0.9415 - val_loss: 0.2094 - val_accuracy: 0.9317\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1929 - accuracy: 0.9450 - val_loss: 0.2086 - val_accuracy: 0.9289\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2024 - accuracy: 0.9396 - val_loss: 0.2095 - val_accuracy: 0.9375\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1985 - accuracy: 0.9410 - val_loss: 0.2072 - val_accuracy: 0.9352\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1995 - accuracy: 0.9397 - val_loss: 0.2040 - val_accuracy: 0.9340\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.2042 - accuracy: 0.9412 - val_loss: 0.2025 - val_accuracy: 0.9340\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1956 - accuracy: 0.9434 - val_loss: 0.2029 - val_accuracy: 0.9368\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1911 - accuracy: 0.9424 - val_loss: 0.2019 - val_accuracy: 0.9317\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1890 - accuracy: 0.9420 - val_loss: 0.2012 - val_accuracy: 0.9359\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1984 - accuracy: 0.9359 - val_loss: 0.2028 - val_accuracy: 0.9368\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1988 - accuracy: 0.9414 - val_loss: 0.2004 - val_accuracy: 0.9349\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1886 - accuracy: 0.9424 - val_loss: 0.2004 - val_accuracy: 0.9343\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9446 - val_loss: 0.2005 - val_accuracy: 0.9311\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1778 - accuracy: 0.9451 - val_loss: 0.1989 - val_accuracy: 0.9365\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1822 - accuracy: 0.9456 - val_loss: 0.1997 - val_accuracy: 0.9394\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1827 - accuracy: 0.9485 - val_loss: 0.1981 - val_accuracy: 0.9390\n",
      "Epoch 25/100\n",
      "  1/735 [..............................] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-079ee5943075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid search values\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "all_train, all_test = list(), list()\n",
    "for param in values:\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, kernel_regularizer=l2(param),activation = \"relu\", input_dim=18))\n",
    "    model.add(Dense(5, kernel_regularizer=l2(param),activation = \"relu\"))\n",
    "    model.add(Dense(3, kernel_regularizer=l2(param),activation = \"relu\", input_dim=18))\n",
    "    model.add(Dense(1, kernel_regularizer=l2(param),activation = \"sigmoid\"))\n",
    "    model.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "\n",
    "   \n",
    "    # fit model\n",
    "    model.fit(X_train, y_train, validation_split=0.30 ,batch_size = 10, epochs = 100) \n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Param: %f, Train: %.3f, Test: %.3f' % (param, train_acc, test_acc))\n",
    "    all_train.append(train_acc)\n",
    "    all_test.append(test_acc)\n",
    "# plot train and test means\n",
    "pyplot.semilogx(values, all_train, label='train', marker='o')\n",
    "pyplot.semilogx(values, all_test, label='test', marker='o')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3351,   83],\n",
       "       [ 115,  951]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.digitalocean.com/community/tutorials/how-to-build-a-deep-learning-model-to-predict-employee-retention-using-keras-and-tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
